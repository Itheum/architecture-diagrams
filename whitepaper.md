# Abstract
Itheum is the world's 1st `decentralised data brokerage`. The platform transforms your personal data into a highly tradable asset class. It provides `Data Creators` and `Data Consumers` with the tools required to "bridge" highly valuable personal data from web2 into web3 and to then trade data with a seamless UX that’s built on top of blockchain technology and decentralised governance. We provide the end-to-end platform required for personal data to be made available in web3 for the first time in history and enables many more wonderful and complex real-world use cases to enter the web3 ecosystem. Itheum provides the core, cross-chain web3 protocol required to enable personal data ownership, data sovereignty and fair compensation for data usage - and this positions Itheum as the `data platform for the Metaverse`.

**Editor’s Note: This blog is not meant to be investment advice nor a solicitation for acquisition of Itheum's tokens. Full Disclaimers are available at the bottom of this document**



      Table Of Contents
        [Introduction](#intro-1)
        [Multi-Chain Strategy](#multi-chain-1)
        [Multi-Chain Technical Design Goals](#multi-chain-1a)
        [Cross Chain Tokens](#cross-chain-1)
        [Itheum Token](#tokenomics-1)
        [Types of Direct Sale](#types-on-1)
        [Buying Data](#buying-data-1)
        [Enabling Personal Data "Proofs" within Smart Contracts](#data-proofs-1)
        [Our 5-stage Product Development Process](#product-process-1)
        [Data Coalitions](#data-coalitions-1)
        [Data NFTs](#data-nfts-1)
        [Data Streams](#data-streams-1)
        [Data Vault](#data-vault-1)
        [Trusted Computation Framework](#trusted-1)
        [Regional Decentralisation Hubs](#decen-hubs-1)
        [NFMe Technology](#nfme-1)
        [Decentralised Governance](#governance)
        [Fraud Detection — “Gaming” the system](#fraud-1)
        [Key Terms of Reference](#refs-1)
        [Disclaimers](#disclaimers)



# Introduction <a name="intro-1"></a>

Everyday, billions of people give away their personal data to organisations in return for some service or product. They sign up to apps, websites, social networks, make online purchases, use digital banking for their day to day transactions, use wearables to monitor their health and use countless other digital services run by commercial profit-seeking organisation who absorb their personal data and put it into locked up data silos.

These organisations then use your personal data to learn more about you and people like you. They then create more products and services for you to buy and get hooked onto to… they call this "stickiness"; and their objective is for you to keep coming back and to share more data.

Some organisations (usually the largest and most influential) can even use your data to influence your thinking and ideas or even resell your data to [3rd Party Data Brokers](https://www.avast.com/c-data-brokers) (independent commercial organisations). These 3rd Party Data Brokers lurk in the shadows and "deal in the personal data trade" making millions of dollars of profit by packaging and selling your data to other organisations. There are over 4000 3rd Party Data Brokers in the world today and they have over 3000 Data Points collected on each one of you! The entire Data Brokerage industry is worth over $300 Billion USD each year and the person generating this data (You!) have no idea how your data is used nor do you get any form of compensation.

At Itheum, we believe that YOUR DATA IS YOUR BUSINESS!



---



# What is Itheum? <a name="intro-2"></a>

Itheum wants to change this current toxic model for personal data collection and exchange and level the playing field — where the commercial enterprise and “you” (the data creator) equally benefit from the trade of personal data.

Itheum empowers data ownership in the metaverse and brings new market value to your data. It enables this by providing “decentralised data brokerage” technology. It’s a suite of tools that enable for high-value data to be bridged from web2 to web3 and then be traded via peer-to-peer sales. It allows for “viral adoption” via our creative Data NFT technology and our innovative Data Coalition DAOs (which bulk sell your data). It also aims to be fully privacy-preserving, regulation-friendly and cross-chain; making it the most comprehensive core blockchain data infrastructure available in the market with use-cases in both the enterprise and consumer space.

It provides 2 fundamental products (that when used together) will flip the dynamic of personal data collection and exchange.


---



# Our Core Products <a name="intro-2"></a>


## Data Collection & Analytics Toolkit <a name="intro-2"></a>
*Tools for structured and rich personal data collection and analytics.*

Organisations can use the Itheum “data collection and analytics toolkit” to seamlessly build apps and programs that can collect structured and rich personal data from users and and also provide visual trends and patterns on the collected data (usually using fully anonymous or semi-anonymous analytics to protect the “data creator” — i.e. the user who provides the data)

With this product, Itheum provides **real-world value and adoption** — and in return we generate **highly structured and outcome oriented personal datasets** (i.e we normalise what user data looks like across organisation silos)

This product is essentially a fully featured personal data and analytics platform offered as a PaaS (platform as a service) to organisations. For example:

1. A health and wellness company can use the Itheum data collection and analytics toolkit and embed it into their apps; enabling the collection of health data like blood pressure, fitness/activity, sleep quality and then visualise trends and patterns of their app userbase.

2. A financial organisation can use the Itheum data collection and analytics toolkit to collect scheduled data via customised surveys or questionnaires, triggered by certain actions related to spending patterns — the trends and patterns can then give them more context of their customers’ spending habits.

Itheum already has multiple apps and programs using the collection and analytics toolkit — your can read about these real-world [case studies](https://itheum.com/#case-studies) here

With this product offering, we are enabling the creation of **highly-structured, outcome-oriented and normalised personal datasets** ([for e.g. have a look at the data that is collected as part of the OKPulse program built on Itheum](https://okpulse.life/#insights))

… and this leads us to our 2nd and **more important product** offering.



## Decentralised Data Exchange (Data DEX)  <a name="intro-2"></a>
*Suite of web3 tools for seamless trade of personal data.*

This product enables you (the owner and data creator on personal data) to own and trade your personal data that was collected by the organisations who built on the Itheum “data collection and analytics toolkit” product. It unlocks the personal data form these organisation silos and lets you earn a passive income by trading your personal data on the open market with other organisations who can derive value from the datasets.

So in those same examples given above:

1. If you use that health and wellness company’s app, you get to own your own data and then sell the health and wellness data you collect as part of your subscription to that app using the Itheum data DEX.

2. If you use that financial organisation product, get to own your own behavioural data and sell it as your choose to anyone else on the Itheum data DEX.

As your personal data was collected as part of a real-world product or service, it’s **highly-structured, outcome-oriented and normalised** — which means it’s highly valuable to many organisations across the world looking to build high quality datasets to power their machine learning backed business analytics engines.

This is the real value of Itheum and our key differentiator when compared to other blockchain based data platforms or self sovereignty solutions. They struggle to gain any real momentum as their products cannot effectively be used in the real-world. Itheum wants to focus on real-world adoption and our 2 products are a **balanced approach to adoption and decentralized self sovereignty.**

Using the Itheum Data DEX, you can sell your data via a peer-to-peer, direct sale method or use our Data Coalition technology and align to a decentralised entity (backed by a DAO) which will sell your data on your behalf (whilst acting on your best interests) and compensate you after the successful sale of the data. Data Coalitions are explained in more detail in a below section, but they are a bit like _decentralized [credit unions](https://www.mycreditunion.gov/about-credit-unions/credit-union-different-than-a-bank) - [View a view on Credit Union Philosophy](https://www.youtube.com/watch?v=8RbksH4LS8U)_— who by representing many members (DAO stakers) have the collective bargaining power on who can buy your data and for what it can used for (i.e. they trade on behalf of their members interests)

The Data DEX is extremely powerful; it allows you to secure sensitive personal data in secure data vaults, it allows you to wrap your data as a NFT so you can earn royalties on any re-sale of your data (all these revolutionary features are provided in detail in below sections). It’s also fully cross-chain compliant (all EVM basked blockchains).

**In summary;** Itheum converts personal data into a new asset class that can be traded in the new blockchain based economy. It provides the complete package - data collection and analytics toolkits that increase the quantity of high quality personal data and the decentralised cross-chain personal data trading platform. Enabling the creation + exchange of high value personal datasets.

So what are you waiting for? Read on to learn more about the Itheum platform and join the Itheum community and be part of the real-world revolution in personal data sovereignty technology.



---



# Market Landscape & Adoption Strategy <a name="intro-2"></a>
The "personal data sovereignty" market landscape is growing rapidly with many traditional web2 enterprises and blockchain tech stack based web3 companies launching and providing solutions to meet the growing global demand for data platforms that empower the "data creator" and enable better regulation of personal data.


## Key web2 and web 3 Competitors <a name="intro-2"></a>
In the web2 space there are highly innovative companies like [digi.me](https://digi.me/) and [Solid](https://solidproject.org/) (a company founded Sir Tim Berners Lee - the inventor of the internet) and in the web3 space; we have platforms like Ocean Protocol, Streamr and Fractal along with newer platforms like Cirus Foundation and Swash. The growth in this space signals the growing need for platforms like Itheum - which aim to underpin the data tech infrastructure needed for future growth in the data sharing space.


## What Makes us different <a name="intro-2"></a>
Itheum provides a new pradimn to solve the same issues our competiors are trying to solve. 

### Not all data needs to enter "blockchain"
Many of our competiors are aiming to stream or on-board **all raw data** into blockchain powered tech stacks. We feel that it's impossible for any distributed system to be able to handle this amount of data. With petabytes worth of data being generated every second, it's not feasible to work with these kinds of volumns and overlay any "consesnsus" or enforce anny fixed standards. Raw data in this valumn is also not worth a lot as it takes a lot of time to process and extract any value from it. Itheum takes a different approach to the problem and aims to generate and unlock highly-structured, outcome-oriented and normalised personal data. Our data collection and analytiucs toolkit allows for such datasets to be created with eash (as evidences by OKPulse for example) and then sold as a highly valueable, context rick dataset. We also allow for such rich personal data based datasets to be grouped togetehr and sold in bulk with our Data Coalitions tcehnology.

### Data needs to be traded across chain
Itheum also is building from day-1 to enable for data to be traded across blockcahins, we believe the future web will be built "multiple blockchains" and inteerroprability is key. With data (especially) we need to ensure that it can flow between blochains with ease. For e.g. with Ithem, you can place data for sale on Ethreum and purchase access to it on POlygon.

## Proivde the "full stack" approach
Itheum will provide the entire stack needed for valueable data to be generated, unlocked, stored, computered and traded. We are the only platform in the market that offers this comprehensive all in one infrastructe. 

### Focus on "viral" adoption
Itheum aims to have a viral go-to-market stragey that removes the barrier for growth, most competitors products are hard to use or complex to udnerstand and therefore adotpion is slow. In the web3 space, there are strong naratives around "fun" uses like NFTs and Gaming which bring in large amount os users...



## Go-to-market strategy <a name="intro-2"></a>



### Viral Strategy (B2C)



### Strategic Growth Strategy (B2B2C)



## Enterprise Use Cases <a name="intro-2"></a>



## The UX 1st Approach to adoption <a name="intro-2"></a>



---



# Data Collection & Analytics Toolkit Components <a name="intro-2"></a>
The following are the key components that come together to make up the Data Collection & Analytics Toolkit.


## Smart Data Types
[IMAGE]

The core element of the Data Collection & Analytics Toolkit is a concept called “Smart Data Types”. There are core building blocks that you can use to build advanced data collection apps. Think of them as the “composable elements” that can be used to generate high value data.

Smart Data Types are a revolutionary concept to data collection that’s native to the Itheum platform. The core Itheum team will regularly build new Smart Data Types and add them to the library. There will also be a public marketplace of 3rd party Smart Data Types produced by our community. 3rd party Smart Data Type developers will be incentivised to contribute their their work with token incentives and grants released by the "Itheum Ecosystem Fund".

Here is an example of a Smart Data Type that is available for use today for the Health and Wellness industry : https://itheum.com/smartdatatypes/blood-pressure-left-arm-sitting

Here are all the other available Smart Data Types: https://itheum.com/smartdatatypes



## App Builder
[IMAGE]

The Data Collection & Analytics Toolkit provides interfaces for app developers to build highly flexible data collection and analytics experiences. Apps can be built using our "no-code" toolkit available in the "Management Portal". The "no-code" approach allows for a click and build approach to data collection and analytics, where you can reuse prebuilt templates for scheduled data collection or build out your own custom schedules and include tools from a already built collection of Smart Data Types, engagement channels (e.g. Email, SMS, Telegram), data visualisations, machine learning analysis layers (e.g. sentiment analysis), reports, alerts/thresholds (e.g. irregular data pattern detection), video education and many more tools. 

You can also freely "clone" existing apps and build on top of them. As an example; if you like the [OKPulse employee wellness app](https://okpulse.life) - you can clone it and build on top of it by adding new  Smart Data Types and data visualisations. We are also working on releasing an SDK and API for people who would like to build apps on Itheum using a programming interface.


## Omnichannel Data Collection
[IMAGE]

In order to reach the broadest user base and bridge as much highly structured, outcome oriented data from the web2 world into the web3 world; Itheum aims to support a wide range of data collection "channels". Channels are pathways from which data is actively and passively collected from users. 

Itheum currently supports automated data collection via Email, SMS, Telegram and Facebook Messenger. We are also actively working to support Slack, Voice (via automated telephony calling and speech-to-text collection of data) and WhatsApp. Itheum is also building an iOS and Android mobile app that will be be able to integrate with your mobile platform's existing secure data vaults (Apple health and Google Fit) and automate the collection of valuable health and wellness data. 

The platform will also support various 3rd party, on-chain and off-chain (Data Adaptors (Fitbit, Garmin, Open APIs, The Graph, ChainLink etc))[data-adaptors-1]


## Automated Data Collection Schedular
[IMAGE]

Apps built on the Itheum will actively and passively collect data from users and bridge seamlessly this data into web3. Highly structured, outcome oriented data can be collected by using Smart Data Types and these data types usually need to be collected at a pre-defined, structured schedule for them to provide the most value. 

Using the built in `Automated Data Collection Schedular`, you can schedule data collection based on granular conditions and timetables. You can pick the day and time data needs to be collected, you can skip certain days or collect weekly, forth-nightly or monthly, you can trigger other specific data to be collected based results of a previous data point or result and also use other customised logic for scheduled data collection. 

For example; in the "Red Heart Challenge" program - blood pressure from you left arm is collected daily but on the weekends, blood pressure data is collected from your right arm. Using this schedule, we can derive using data analytics on the "variance of left vs right arm collection" and "weekday vs weekend collection". The automated Data Collection Schedular provides the ability to enable rich data collection and increase the value of the final data.

## User Portal
[IMAGE]

Every user who joins and participates in Itheum programs (e.g. Red heart Challenge, OKPulse) will get access to their very own `user portal`. The user portal provides them with full visibility on the data that have been collected on them and will provide the user with the tools to edit or delete data at anytime. The user portal enables full visibility, management and control of the user's interactions with Itheum Apps. 

Along with providing users with control over their app subscriptions and data, the portal can also be used by users to manage their account preferences, watch education modules (see below), participate in rewards programs (swap engagement reward points for gift-cards) and join new programs. 

The user portal will also be the central hub for "data and privacy control and regulation", where the user can opt in to having their data stored in specific regions or to even completely exit from the Itheum ecosystem and request a full delete of their data assets and history (e.g. "forget-me"). In future; When Data Coalitions provide services like "delegated data usage policy approver" - the user portal can use used by the user to manage the this delegation interface.


## Powerful analytics and insights engine
[IMAGE]

As described above in the Smart Data Types section, each Data Type will have built in `composable analytics modules`. These modules are built by developers and data analysts and will overlay on top of all the collected data to provide unparalleled insights. As these analytics modules are composable, you can piece them together to generate powerful analytics and gain insights on the data collected via your apps. 

The insights engine can also make use of some core analytics modules built by the core Itheum team. As example of such a module is the `AI Sentiment Analysis` layer - this layer can be applied to any user-entered input collected by your apps. In the OkPulse App, the AI Sentiment Analysis module is used to analyse the written sentiment of an Employee as they interact with the app. The output from this layer is then used to detect levels of stress and anxiety among employees as they respond to certain data collection metrics. 

## Management Portal
[IMAGE]

Users who build and run Itheum Apps will get access to a management portal, this is akin to an admin portal that provides full management features over the the apps they are running and the users who are enrolled into those apps. This portal will allow an admin user the tools to manage their Itheum apps (update app configurations and settings, add new apps, change engagement channels for data collation, upload new education modules etc) and also manage their users (manually onboard new users, change password and access control for users, see user progress, add users to new programs etc). 

The portal will also provide the comprehensive data reporting features that allow the user to view cutting edge data analytics which are produced by the `Powerful analytics and insights engine`. The management portal is the "control panel" for everyone who runs itheum apps.


## Built In Video Education Studio
[IMAGE]

Itheum aims to generate very high quality personal data but this can be a challenge as the problems of bad data quality are very common in the data tech industry. Especially when the data is generated by an end user and not a machine (like a sensor). For example; in the health and wellness industry - the problems associated with bad "patient generated data" makes it very hard for clinical staff to make automated diagnosis or dispositions, as there is a high possibility that the data might have been incorrectly generated or entered by the end user (patient). These problems are not unique to the health and wellness industry and are common across any sectors where end-users are responsible for generating and submitting their own data.

To improve the quality of data that is produced by Itheum apps, we have implemented an "education layer" that's built into the Itheum platform. App developers are able to create or reuse education videos that guide the end user on the proper methods of data generation and collection. In the "Red Heart Challenge" app for example, all the users of the app are presented with education videos on the correct method to take blood pressure from their arms whilst at home and how they should submit it. 

the Itheum Management portal has a video studio that allows you to record videos or reuse videos from public channels like YouTube. Users are also rewarded for watching these videos, with engagement points being handed to users as they complete video education modules. With users earning rewards to be educated of data collection, their engagement rates increase and Itheum generates higher quality data. In future, Itheum will also allow 3rd party education content provides to generate education videos for use within the Itheum App ecosystem.

## Dispense rewards for compliance
[IMAGE]

The data collection apps built on Itheum aim to have built in mechanisms to boost user engagement and compliance. As higher user engagement leads to higher quantities of data, these incentive mechanisms are invaluable to the system. Users who join the `Data DEX` to connect their Itheum Apps and then bridge and trade their data on the blockchain, are able to earn MYDA tokens in return for access to their data. But this requires users to have web3 experience and it can be a limiting factor initially where Itheum's apps may have many users who are yet to enter the web3 technology  ecosystem (wallet usage, token purchase on DEX/CEX etc).

To enable the widest adoption of Itheum in web2 and web3; the Itheum platform also introduces a `web2 rewards system` - where users who earn "traditional rewards points" as they engage with the apps they join. Users can earn points for completing data collection tasks on time, watching education videos, logging into the platform to check progress etc. This reward system is very similar to the mainstream royalty points system that users will be familiar with, where you can earn points for credit card usage, frequent travel and for shopping at the grocery stores. The Itheum app platform's rewards points can then be redeemed in the reward store for real world gift cards or redeemed for MYDA tokens in the Data DEX. 


## Full White label Support
[IMAGE]

Apps developed on the Data Collection and Analytics toolkit will be built by commercial enterprises and also academic and research institutes. We have seen this already with OKPulse, which was built by a corporate wellness institute and Red Heart Challenge which was co-designed and built by an academic institute. These entities will usually have a target user-case they'd like to engage with and often require the entire app experience and data collection communication to be "white labeled". 

White Labelling includes using your own domain names, logos and branding, email and mobile numbers, support ticketing systems etc. By white labelling an Itheum App, app developers can boost adoption with their users as the entire user experience will be branded to something they can be trusted. To enable this requirement we have built in full white label support for Itheum Apps and feel that this is a huge selling point for mass adoption in both the commercial and non-commercial sectors.


## App & Smart Data Type Marketplace
[IMAGE]

Anyone can participate in the Data Collection and Analytics toolkit ecosystem and build Smart Data Types and Apps. For Apps built for use within the not-for-profit and academic sectors, Itheum will offer the toolkit absolutely free of charge. For commercial use-cases Itheum will charge a nominal fee (we will offer it as a Platform-as-a-service with a nominal fee that ensures that the price point is accessible to small-to-medium businesses to ensure they can participate in the personal data collection industry). 

As detailed above, all Smart Data Types and Apps are "modular"; which means that you can clone them and build on top of them. This makes Itheum highly composable and extensible and will provide huge opportunities for innovative data collection and analytics solutions to come into existence.

All new Smart Data Types and Apps build built on Itheum will be available in a `Itheum Marketplace`. Most of them will be available free of charge, but we will also provide a mechanism for Smart Data Types and App developers to build solutions that can be sold or licensed. This provides a dynamic marketplace for data collection and analytics innovation and an opportunity for 3rd party developers, data analysis, data scientists, product owners to earn some income.


---



# Decentralised Data Trade <a name="data-trade"></a>

The DEX allows for the seamless sale of personal data by “data creators”. The sale, verification and ownership accreditation of the data is handled on-chain but the actual data being sold is kept off-chain. 

There are a few reasons for this:

1. On-Chain storage of large datasets is not feasible. Blockchains are not built for the storage of data and doing this will be costly and also pollute the blockchain.

2. On-Chain storage of whole data or segments of data can also lead to privacy and data sovereignty issues as the blockchain is a fully open and transparent tool.

As such the sale of data is facilitated via a hybrid on-chain/off-chain model.

1. Data is first validated and hashed. The validated and encrypted dataset is uploaded to a centralised, secure storage location to a hidden (non-public) destination.

2. It’s important to note that the above “storage location” is centralised. rather than being decentralised via IPFS (for example). Again there are reasons for this — this mainly has to do with the data sovereignty issues of data where certain countries or regions require data to remain within geographical boundaries. We are working on a solution that allows for decentralised, region based storage or via validated, decentralised node based storage. This will be handled as part of the *Data Coalitions* concept where privacy, security and regulatory requirements for storage of data is handled via a delegated, authorised coalition who will manage these “under the hood”

3. The hashed value and the identifier for the location is stored on the blockchain.The availability of this new data for sale is then “Advertised” — allowing for this new dataset to be “discovered” and then purchased via on-chain facilitation.

At this point in time, there are “two groups” of data you can sell on the DEX. They are as follows:



## 1) Selling Core Itheum Data <a name="selling-2"></a>

The core Itheum platform is a general purpose personal data collection platform where organisations can build applications (which require structured user data) using the core toolset that Itheum provides. 

Examples of these structured data collection applications are:
- Red Heart Challenge (https://itheum.com/redheartchallenge)
- OKPulse (https://okpulse.life/)
- Other Programs (https://itheum.com/#case-studies)

The applications are called “programs” within the Itheum platform and these programs can onboard their own “end users’. These end users generate a lot of personal data and have a “Itheum user portal (called CareView)” for them to have full visibility of the data they have provided.

This demo video shows you an example of the end user portal (CareView)for OKPulse (https://www.youtube.com/watch?v=ITONnseBFV4)

The CareView portal allows the end user (data creator) to link their Ethereum, Polygon, BSC or Avalanche account to their Itheum platform account. Once they have done this they can then use the Data DEX to load the raw datasets they have generated and put them up for sale.

As the data collected via a Itheum program/application is **fully structured and outcome oriented**, for example — Red Heart Challenge data is centered around the self management of Cardiovascular disease management and OKPulse is around the proactive monitoring of Employee health and wellness issues — it is very valuable for a data buyer/consumer who wants to align analytics discovery or outcome analysis around a certain topic.

When this data is grouped together with multiple people who have joined the same program/application via a “Data Coalition (see below)”and augmented with personal data via the “Data Vault (see below)” then the value of the data can grow exponentially as the quantity and quality of the datasets grow.



## 2) Selling Any Arbitrary Data <a name="selling-3"></a>

The Data DEX also allows you to sell any arbitrary data using the same on-chain facilitation process. This allows anyone with a crypto wallet to upload and sell datasets via the DEX. This reduces the barrier of entry for end-users and also provides them equal opportunity to participate in the shared data economy. At this stage we allow for the sale of the following arbitrary datasets.


### 2.1) Facebook Profile Data

As you may know, Facebook opened up the option for individuals to download all their data in “bulk”. This was a feature that was released by Facebook after pressure from data advocacy regulators who wanted to ensure individuals had the right to download their personal data off the Facebook platform should they ever want to delete their Facebook account or move to a new social media platform.

The Itheum Data DEX will allow for the above later scenario (of moving to a new social media platform) to be handled seamlessly. For example, an individual can download all their Facebook data and advertise it for sale on the Data DEX, they can then align with a __Data Coalition centred around the responsible usage of data by Social Media type organisations.__ A new social media platform can then view the “Facebook user datasets” managed for sale by the Data Coalition, agree to the responsible terms of use and purchase the data in bulk. The new social media platform uses the data DEX to bootstrap and migrate Facebook users to its platform directly via an authorised, delegated owner (Data Coalition) of the end-user data. The end-user (original Facebook user) then gets the payout from the Data Coalition and can also view the complete audit trail of data transfer between the social media platforms.



### 2.2) Any Other General Data

The data DEX also allows for the on-chain sale of any other type of data. For example, you can create a dataset of all the brands and products you, your family and friends like, all the reviews and ratings of your favourite restaurants, personal fitness or other wellness data. You can also create and sell other interesting IP centric general datasets like utterances to intent mappings which can then be used by organisations to train NLU and speech to text applications. For example, a hospitality booking organisation (who provide telephony services or conversational tools like chat bots to help users make a booking) might already be spending a lot of investment in continuing to study end-user speech-to-text patterns and map them to intents that are relevant to their industry. They can sell the utterance-to-intent mapping data on the Data DEX to recoup some of their spending in producing this IP.



---



## Types of Direct Sale <a name="types-on-1"></a>

As described in the above section - you can use the Itheum Data DEX to sell personal data using on-chain tools that coordinate the trade between buyer and seller. On the Data DEX, there are fundamentally **two types of direct sale** that can occur. We mention “direct sale” here as it’s the seller (Data Creator) who decides which type they prefer and initiates the trade process within those constraints. In a later section we will describe how data can also be sold indirectly via a delegated Data Coalition, but for now let’s focus on the following two direct sale types.

1. Sale of Data Packs
2. Sale of Data NFTs

let’s now dive into these two types individually and understand the difference.



### Sale of Data Packs <a name="types-on-2"></a>

Once a Data Creator decides to sell their personal data, the default method of sale is the sale of Data Packs. Data Packs hold a reference to the type of dataset they are putting up for sale and contains some metadata around it. For example, it provides a preview of the data, when it was created, terms of use, the link to where the data can be securely downloaded from (after sale is complete) etc. Once the user creates a Data Pack it gets advertised for sale ‘on-chain’. Once this on-chain advertising process is completed, the original “data hash” and the “transaction reference” of the advertising process and the data pack is also stored as metadata against the Data Pack. A MYDA price is automatically calculated based on the type of data and market demand for the type of data. In future, we will also support the Data Creator picking their own price for their data. Sale of Data Packs can be described as direct peer-to-peer sale.

Once the on-chain advertising process is complete, buyers will see the Data Packs for sale in the “Buy Data” section of the DEX. The buyer can the pay the MYDA cost for the data and then “own” a copy of the data (these copies are called **Data Orders** and appear in the **Purchased Data** section of the DEX). As part of the buying process they agree (on-chain) to abide by the “terms of use”. A record of this agreement is stored on-chain as part of the purchase and serves as an immutable audit trail for this agreement. One key point to note is that in this type of sale — **the re-sale of data is NOT permitted.**

A data creator should choose to sell data as a Data Pack if they are have the following requirements:

- Sell multiple (potentially unlimited) copies of their data to buyers around the world

<br />
- Don’t want their data to be re-sold by the buyer (i.e. the buyer can only use it as per the terms of sale and for their own use/consumption — __if a buyer breaks their agreement and resells the data, the owner will have the ability to detect this and mediate a conflict resolution process — but only if the sale is handled by the Data Coalition — more on this below — but the seller unfortunately won’t have a direct method to track the re-sale or get any benefit from it. e.g. royalties).__

<br />
- Only allow for their personal data to be sold on the Itheum Data DEX (no other decentralised marketplace will display the Data Pack for sale — this is because it’s not built on any open blockchain standard like ERC 20 or ERC 721 that allows for interoperability). This can be looked at as a benefit if the Data Creator wants to limit exposure of their data (as it’s for sale in only one marketplace)



### Sale of Data NFTs <a name="types-on-3"></a>

A Data Creator can also choose to sell their personal data as a NFT (Non Fungible Token). This makes a lot of sense as personal data is very unique and NOT fungible (watch this short video to understand the difference between (fungible and non-fungible)[https://www.youtube.com/watch?v=OXCJxy0f4Ic]). This allows for the Data Creator to have more control of their data and can align to NFT features that make their data grow in value (rarity/scarcity) and increase exposure of their data assets due to the interoperability and portability NFT standards have in the blockchain ecosystem.

Data NFTs are described in more detail below and use the ERC 721 open standard to coordinate and facilitate the NFT contract between parties involved in the trade.

A Data Creator should choose to sell data as a Data NFT if they are have the following requirements:

- Sell a “limited number” of copies of data: This is the same concept as the **limited edition NFTs** we see in the market today. Having a limited number of copies of the data will create organic growth demand for the data as the buyer will realise the rarity and scarcity of the data. For example, if a Data Creator “only mints 2 copies” of their DNA sequencing result — this has a lot of value to a buyer trying to build a dataset of similar DNA sequencing results as there are only 2 copies available for sale. If there were virtually unlimited copies available (as you would have with Data Pack based sale) — then the perceived inherent value for the data will be less.

<br />
- Allow for the “re-sale” of data: The data creator is happy to allow for the re-sale of the NFT packaged data by a buyer. This opens up a lot of opportunity for the data to grow in value as the buyer might have a better ability to “market the data”. This also opens up opportunities for secondary markets where “verified, legitimate data brokers can exist on-chain” — a revolutionary concept and a futuristic solution to the problem that exists today where centralised data brokers are selling your personal data without your knowledge.

<br />
- Benefit from the “re-sale” of data via Royalties: Your data is essentially your IP (much like a song by a music artist or a book by an author) and packaging your data and selling it as an NFT will allow you to earn a Royalty on the resale of the data. For example, you can choose to nominate a 10% royalty condition and if a buyer re-sells the data, 10% of the sale will be transferred to your account.

<br />
- Benefit from multiple NFT marketplaces: As Itheum Data NFTs are built on the ERC721 standard, they immediately have interoperability with all the NFT marketplaces that support this standard (OpenSea, Rarible etc). This significantly increases the audience and therefore increases your potential to sell.

{% youtube f5FtZl6XGSY %}
> _Demo 1: minting and selling Genomics data as a Data NFT_

<br /><br />{% youtube SmDGCt45qZU %}
> _Demo 2: minting and selling Blood tests results as a Data NFT on OpenSea_



## Methods for Buying Data <a name="buying-data-1"></a>

One-off datasets advertised for sale on the Data DEX are called “Data Packs”. As described in the above section “Selling Data”, there are various types of data that can be put up for sale on the DEX. On top of the one-off data sets, the Itheum Data DEX also allows for the sale to “Data Stream subscriptions” (see in a below section titled Data Streams)

Data is sold via two channels:

1. Direct between Data Creator and Buyer
2. Via an intermediary, Authorised Data Coalition

Anyone with a crypto wallet can become a buyer of data packs or data streams under certain conditions.

1. They need to have MYDA in order to pay for the data. The MYDA is sent direct to the data creator (if the sale is direct between data creator and buyer) or to a Data Coalition if the Coalition is “brokering the sale”.

2. Each data pack or stream will have an associated “terms of use”, the buyer agrees to abide by the nominated use. There will be dispute and conflict resolution processes in future to protect the seller from misuse. (if the sale is direct between data creator and buyer)

3. If the purchase is via an authorised Data Coalition, then the buyer needs to adhere to the terms and condition of use as per the Data Coalition and also put in collateral in the form of MYDA for a certain period of time (until the buyer earns a higher credibility score) – data sold via a Data Coalition has a more robust misuse remediation and dispute resolution process handled via decentralised governance.



## Pricing Data <a name="types-on-1"></a>



---



# Data Dex Components <a name="data-dex"></a>



## Peer to Peer Data Trade <a name="peer-trade-1"></a>
The base functionality that's available when you first log into the Data DEX is the ability to discover and trade data with your "direct peers". You will be able to see all "advertised data" from others and also "advertise" your own data in the data marketplace. As detailed in the section (Decentralised Data Trade)[#data-trade], you can advertise your data from apps that you have joined that's built on Itheum's data Collection and Analytics toolkit or you can also advertise any "arbitrary data" that you own.  

When you place data for sale you will nominate a purchase price in MYDA, which is effectively the price for a Data Consumer to access your data. If someone wants access to your data, they will transfer the MYDA requested and in return get access to the data for use based on the "Terms of Use" that you specify. The market operates completely in a "peer-to-peer" manner where there is absolutely no intermediaries involved in the transaction. Data Creators and Data Consumers deal direct with each other and the entire process is mediated using Smart Contract technology.


## Data NFTs <a name="data-nfts-1"></a>

Data is an asset in itself and personal data is a “unique asset” as no two personal datasets are the same. Highly personal or sensitive datasets can essentially function as a NFT allowing for uniqueness and limited availability.

For example, your might want to share your DNA or partial sequencing results under the “research” terms and conditions — but you may want to limit how many buyers can purchase it and use it (controlling distribution)— data NFTs allow you to do this.

To make it more aesthetic to trade, we convert valuable datasets (usually this will be in JSON or data in any another interoperable format) to a unique visual representation of that data (which will be in a deterministic, random image abstract format) — to do this we will an algorithm for image generation based on the unique signature of the data.

Packaging and trading your personal data as NFTs have the following benefits (when compared to regular one-off trade using the DEX):

1. Limit the distribution of your highly sensitive or protected datasets to a smaller amount (similar to limited edition NFTs we see in the market today)

2. You can choose to earn royalties if your data is resold. You can limit the distribution of your data but should a buyer resell your data NFT, you have the option to earn a % as royalty. This is a game changer and can prove to be a steady secondary income stream for you. This is especially true if your data is curated into a data coalition which has a high buyer demand.

3. Once data is packaged and tokenised as an NFT, it can be traded on any NFT marketplace (e.g. Opensea - *we already support this interface in our testnet*). This significantly increases the selling power of your data as the audience for your data increases. Read about it here on our blogpost [Selling your Itheum Data NFT on OpenSea](https://itheum.medium.com/selling-your-itheum-data-nft-on-opensea-f2c8bcef089b)

4. Your unique data will be minted with an aesthetic “generative art wrapper” created using the unique signature of the data. E.g. your DNA data can be represented as piece of unique art (similar to Autoglyphs or other generative art) which is sort after as it has rarity, creativity and actual utility.

## What real-world trade characteristics do **NFT wrapped data assets** provide?
Let's look at some key trade characteristics we can get by wrapping our data as an NFT and then opening it for trade.

When working with NFTs in general, the main actors to consider are:

- Issuing Entity: The issuing entity behind the NFT (in Itheum's case; the **Original Owner** or a **Data Coalition** can be the *Issuing Entity*)
- Original Owner: The original **Data Creator** who choose to sell their data as a Data NFT 
- NFT Holder - The present holder of the Data NFT
- NFT Purchaser - Someone with the intent of acquiring the Data NFT from the present NFT Holder

![image](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/r7geatc5p26z88atfvf4.png)
 

In this example, let's assume *you want to sell your Genomics dataset as a Data NFT.*

1. You use the Ithuem Data DEX to upload your data file and **mint a new Data NFT**. You are the **Original Owner / Issuing Entity**. The NFT is minted with a "proof of ownership" along with other metadata that enables access to the original data file if ownership is proven. All this metadata will be stored on-chain via the standard NFT metadata file schema standards.

2. You then head over to a public NFT marketplace (e.g. OpenSea - where your Data NFT will already be available for sale under your wallet). You place it for sale for .05 ETH

3. **Buyer 1** comes along and purchases the Data NFT as they see value in owning a genomics/DNA based dataset. Transfer of ownership now moves from you to **Buyer 1**. They are now the **NFT Holder**

4. But **Buyer 1** does not intend to use the data for any utility, they are essentially a pure "data trader" and intend to resell the Data NFT at a higher price. They increase the sale price to 1 ETC.

5. **Buyer 2** comes along and wants to purchase ownership of the Data NFT as they intent to use it for their research into topics relating to Genomics. They are now the **NFT Purchaser**. As their data research requires for *absolute truth-fullness in the data quality* (e.g. they may intend to use it to train a ML model for disease diagnosis and need to guarantee that the training data has not been tampered with) - they choose to purchase this data via centralised blockchain based trade *rather than buying it from centralised data brokers or sellers.*

<br />


### Let's look at the list of benefits each actor received by trading data wrapped as a NFT

**Original Owner / Issuing Entity**: 
1. Limit supply of the dataset to just a single item (the can always mint more if they see demand grow)
2. During initial sale on the open NFT Marketplace (e.g. OpenSea), assign a *royalty %* that they get paid during all future re-sales
3. Benefit from all the open NFT Marketplace features to control the sale (duration / minimum period, highest bid etc)

**NFT Holder**:
1. Ability to speculate on future price of non-fungible data and earn profits for re-sale
2. Build Data NFT collections based on market/seasonal demand for certain types of datasets

**NFT Purchaser**
1. This actor gets the most value as they intend to use the contents of the Data NFT (raw dataset) for actual utility.
2. They can view and prove the **provenance** of the NFT using on-chain lookup and clearly identify the **Original Owner**
3. They can view and prove the **lineage** of the NFT using on-chain lookup (Original Owner -> Buyer 1 -> Buyer 2)
4. They can view and prove the **veracity (truthfulness/accuracy)** of the NFT using on-chain lookup of the meta-data
5. The can request formal **transfer of ownership** to own the *IP* if needed and is allowed in the original terms of sale. Although this feature is not an inherent quality of NFTs, it will be mediated via Data Coalitions and our "Decentralised Middleware" service

<br />

> Data NFTs are currently in the "Available in Testnet" stage.


## Data Coalitions <a name="data-coalitions-1"></a>

Independently selling personal data is inefficient and time consuming. Continuing to curate and monitor the “terms and conditions” for each sale as well as to keep track of what data will be used for and by whom will quickly become overwhelming.

Your individual data (both the longitudinal data from your structured programs and highly personal & sensitive data from your vault) — is also not very valuable “when viewed in isolation” — but when your data is “grouped” into clusters of similar people, it grows significantly in value as the volume and quality increases (e.g. your health data is worth > $1,500 if sold as part of a larger dataset). The grouped data then becomes useful for deep analysis or to train machine learning models for example. We believe that this is the future of how data will be sourced on the blockchain to train AI and for deep analytics.

Data Coalitions are DAOs where the "Creators" of the Data Coalition will bond MYDA to form and run it. The creators are called Board Members and they have an incentive to run the Coalition on the best interests of its "Members". Board Members have "stake in the game" with their bond and therefore will need to always act in the best interest of the Members. Board members will also earn a share of the trade, so it's in their best interest to keep their Coalition as robust as possible in order to attract new Members (and therefore more Data). 

Itheum envisions a future where the most successful Data Coalitions will be run my enterprises and SMEs (subject matter experts like legal and regulation experts, commercial data warehouses, academic/research institutes, government departments etc) and will be the perfect balance between commercialisation of data and accountability to end-users (Data Providers). Board Members vote to agree on the terms and conditions and the governance (privacy and security) of the data trade, the parameters they agree to will be made visible to anyone who wants to join the Data Coalition. Users (called Members) can then align to the Coalition who they feel acts in their best interests. 

You then delegate the ownership of your datasets, data streams and data NFTs. The Coalition will group your data into clusters of similar data and sell the data in bulk to a larger column of buyers. In return you can earn a steady value return on your data or choose to lock up your returns for longer term growth of the Coalitions network. 

Data Coalitions also allow for "staking" of MYDA, where anyone can stake their MYDA with a Coalition (you don't HAVE to provide your data) to flag their support for the Data Coalition and to signal that the data within the Coalition is good (Crowd Sourced Data Curation), this allows for itheum to be used by users who want to participate in the personal data economy but who don't necessarily want to provide their data at that point in time. All parties involved in the Data Coalition (Board Members who bond MYDA, Members who share data, Members who stake MYDA are all incentivised relative to their role and stake and earn micropayments after each sale is finalised)

Itheum's Data Coalitions are modelled on the [Credit Union Philosophy](https://www.youtube.com/watch?v=8RbksH4LS8U)

<br />
## Decentralised Board Members <a name="data-coalitions-2"></a>
As introduced above; Data Coalitions are formed and run by a virtual board — they have additional governance responsibility and can mediate / provide conflict resolution, negotiate terms of sale of data with real world entities and other Coalitions etc. Board Members have to bond MYDA into the Data Coalition to ensure they have a “stake in the game”, after which they can stand for election and be voted in by other board members. To prevent hard centralisation, Board Members will serve a fixed term (if required by the Members - it's not mandatory), and after which they will need to rotate out and be replaced with a new board. Board members earn a share of the sale in data (payed out in MYDA) that is housed within the Data Coalition. They can also lose MYDA in case they don’t represent their member’s best interests or conduct an incorrect sale of data (that breaks the terms of sale contract) and need to revoke it and pay back the buyers and compensate sellers for the damage. Although not mandatory, Members will be able to participate in ongoing period votes to express satisfaction of the Board's performance. If satisfaction rates are low for multiple voting points - this will trigger a board rotation clause. 

### Other Notable Properties of Data Coalitions
- Data Coalitions enable "collective bargaining power" for end-users and will be a viable solution to the problem of centralised enterprise data silos that don't provide any value to the Data Creator.

<br />
- DAO based governance and modified proof-of-authority based decision making will be involved in ongoing operations of the Data Coalition. 

<br />
- They will also be delegated custodians of “Data Vaults” and can autonomously trade high value data from the Vaults by attaching it to the other datasets within the Data Coalition.

<br />
- They will also be able to link with the "Trusted Computation Framework" and facilitate the privacy preserving compute-to-data technology handshake, where 3rd parties will be able to run algorithms on the datasets housed within the Coalition without having the identity and privacy of the original Data Creators leaked.

<br />
- They can efficiently facilitate "micropayments" to all its members in return for data. For example, a Data Coalition can have 1000 "members" who contribute data for bulk sale. After each sale, the 1000 members will be sent a share of the earnings via micropayments. Traditional banking payment systems are unable to handle these kind of micropayments due to the overhead of fees and charges - but crypto will be able to facilitate this well.

<br />
- Data Coalitions in future will also trade with other Coalitions and be connected to autonomous machines via a machine to machine type interface. E.g. wearables or EVs who join Coalitions directly and participate in the data economy.

<br />
- As we join new apps or services today we are often promoted to agree to "terms and conditions and privacy policy documents" that are pages long and contain legal jargon that we just don't understand. Many of us do not read this or understand the impact of "agreeing". As some Data Coalitions will be made of of data, regulation and legal subject matter experts - they can in future can provide services like "delegated data usage policy approver", where users can delegate the approval rights to the Data Coalitions who would have previously vetted terms and conditions and privacy policy documents and can agree to them on behalf of the user. This service will be provided to web2 and web3 app developers and we envision this as a "pay per use" product, where the generated income shared with the Data Coalition members.

<br />
- They can allow (if voted by members) for "anonymous cohort analysis" of data trends via tooling provided via our "data collection and analytics toolkit" feature. For example; there may be a data coalition setup for the collection of "fitness and demographic data" - where you, as a Data Creator can align to and sell your wearable data from Fitbit or Garmin as well as append specify demographic data from your Data Vault (e.g. Gender, Age, Ethnicity) to enhance it's value. Anonymous cohort analysis can then be enabled to visualise the type of data under the control of this Data Coalition. This adds more appeal to buyers who can preview data with more detail before committing to buying at a premium price.

![image](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/avoyaf20ah58ysvutla5.png)
> _Anonymous cohort analysis via our data collection and analytics toolkit integration_

<br />
- By default the Itheum Data DEX supports any data uploaded in **valid JSON format**. But there may be some specific data sub-standards that will be more appealing to certain types of niche buyers. For example, buyers who are interested in Health and Genomics data for automated ingestions into their systems - they will prefer a more globally interoperable standard like [FHIR - Fast Healthcare Interoperability Resources Standard](https://en.wikipedia.org/wiki/Fast_Healthcare_Interoperability_Resources). Data Coalitions will be able to mandate this as a *minimum requirement* for its members and ensure that the data being contributed is in the FHIR JSON standard.

<br />
- Anyone can start a Data Coalition but it will take some effort to progress it into an "operational mode" and attract new data to come under it's control. For e.g. if you start a new Data Coalition you will need to bring in Board Members with credibility and who will need to Bond MYDA for their term duration. Once you have filled the minimum requirements for the Board Members, the Data Coalition then enters "operational mode"  and can begin accepting data and MYDA stakes from regular users (members). But being in "operational mode" is not sufficient to attract the best quality data; all details about Data Coalition Board Members are made public - so it's important that you have some commercial experience in data related matters to give you credibility. Any "slashes or disputes" arising from your Data Coalition's trade activity are also made public. This is very similar to how the `Delegated Proof of Stake validator selection` process works, where you can stake your tokens after doing some due-diligence on the validators reputation and past performance. So for a Data Coalition to be successful - it will need to be in a "operational mode" and have some credible "board members" whilst maintaining ongoing trade operational credibility.

<br />

> This feature is currently in the "Detailed Design & Prototyping" stage.



## Personal Data Proofs <a name="data-proofs-1"></a>

In the decentralised DApps ecosystem (DeFi, DAOs or any other application use cases enabled via DApps); *Smart Contracts* enable for agreements between parties to execute based on "indisputable truths". For example, in a DeFi exchange, a trade transaction between two parties can happen backed by the on-chain state data that confirms that the transaction can indeed proceed (e.g. party A has the tokens to transfer and Party B is entitled to receive the tokens based on some pre-agreed above condition). So Smart Contracts enable for trust-less interaction to happen between multiple counter-parties. Traditionally, transactions such as these in finance require a trusted intermediary such as a Bank to coordinate.

But *Smart Contracts do have a key limitation in that the data they have access to on-chain to facilitate such trust-less behaviour is very limited*. We only have data around transaction history and other such on-chain information (e.g. voting outcomes etc). For more complex trust-less applications to migrate to the blockchain, we need "richer, real-world data" to flow into Smart Contracts. *[ChainLink](https://chain.link/) provides this real-world data via their Decentralised Oracle Networks* and enable the technology of "hybrid smart contracts". These hybrid smart contracts use the real-world oracle data to make decisions and carry out transactions between parties. ChainLink enables smart contracts to tap into real-world data like exchange price feeds, weather or sensor data and allows for the contracts to mediate transactions between multiple parties based on outcomes resulting from smart contract code execution backed by real-world data.

But if Blockchain technology was to branch out and handle many more mainstream use-cases, we will need a wider variety of real world data to flow into the smart contract world. One type of data in particular that is not available today (even via Chainlink oracle networks) but is crucial for richer blockchain use-cases - *is Personal Data*.
 
As described in the above section titled "Types of Direct Sale" - the Itheum platform enables *Data Creators to place their personal data for direct peer-to-peer direct sale on-chain*. One of the *underlying qualities of this type of trade is that a "proof of the personal data" is stored on-chain*. This proof is then used (by a Buyer) to verify that the *data's veracity is untampered* before the trade actually happens. 

This features enabled by the Itheum Data DEX can *also be used as a "personal data proof" by smart contracts to execute specific rules that enable transactions on-chain to happen that are backed by personal data*.

## This revolutionary concept is best explained with an example:

**Home Loan Application - Real Word Scenario**
Jack wants to buy a house. He heads over to his bank and requests for a bank loan. The bank needs to carry out a detailed assessment to make sure Jack is actually eligible for the loan (i.e. can he make repayments? what is the risk he will default on it? etc). The bank does a credit check on Jack and finds that his credit history is good. The bank's home loan broker then does an extended personal due-diligence assessment. Jack is asked to provide his financial history, income history and other details about his spending habits, family, dependents and work history. This information is collected using a detailed bank loan application form the bank has prepared as a standard document. Once Jack fills the form he needs to attest the form as holding true information (via a form of statutory declaration that is legally binding). The bank assesses the details on the form and makes a decision to give Jack the loan. Jack uses the loan and buys a house.

Now let's imagine that we want to port this entire scenario to the blockchain and remove as many intermediaries as we can (the bank, the credit history provider, the home loan broker etc.)

**Home Loan Application - DeFi Scenario**
Jack wants to buy a house. He visits a DeFi Lending DApp  that is a DAO (modelled after a real-world credit union but fully decentralised) that allows for borrowing based on voting based approval and on-chain evidence of collateral (e.g. other assets that Jack owns in the same DeFi DApp or other DApps). Jack requests a loan and the DApp begins its automated due diligence process. As part of this process; the DApp invokes another DeFi DApp's Smart Contracts that allows for deep credit history checks (possibly via deep index lookups or via [the Graph](https://thegraph.com/) for more advanced lookups). The credit checks come back positive for Jack. The DeFi Lending DApp then refers Jack to an application form built and run using *Itheum's data collection and analytics toolkit*. It includes all the regular questions asked by banks during loan applications that needs to be asked to an applicant directly (e.g. what is your employment history? your spending habits? your family details and other financial responsibilities? basically all the personal information that is needed to make an informed decision about a borrowing risk but cannot be obtained using blockchain lookups). Jack completes the form and his responses are stored inside the *Itheum Data DEX as a "Data Pack"*. Jack then *Advertises this Data Pack on-chain* and the *proof of his response is published on-chain* and sent to the DeFi Lending DApp as a "personal data proof" and attestation to his responses to the form. The DeFi Lending DApp now has all the information it has to take his application to the final DAO voting panel. The members of the DAO have all the attested information and proof to make a decision on the home loan (collateral confirmation, positive credit history, application form due-diligence responses and on-chain proof). The DeFi Lending DApp is happy with the application and approves the loan and Jack receives the money.

Itheum provides the complete platform for these kinds of *personal data proofs* that can be used for on-chain decision making. Think of Itheum as the next layer of data inflow into the blockchain world. Core blockchains provide transaction data, ChainLink provides real-world event data and Itheum provides personal data proofs direct from the end-user. When used in unison; we can replicate many real world scenarios using smart contracts and remove redundant intermediaries.

{% youtube xq60uTA844c %}
> _Watch more real-world use cases and code demos_



## Data Vault <a name="data-vault-1"></a>

You can store highly sensitive personal data in your data vault. For example; details about your gender, race, sexual preference, prior health conditions, financial history etc.

This sensitive data is encrypted using your own encryption keys (no one else can unlock and view it) and stored in IPFS (no one else can destroy it)

You can then choose to append data from your vault to the regular data you sell on the data DEX. As this gives the “dataset” more context, it becomes more valuable to the buyer — and you will earn more MYDA.

As the data is encrypted using user’s private key we need to enable a frictionless UX during trade between buyer and seller where keys need to change hands with minimum manual involvement between parties; For this purpose, “symmetric key pools” (decentralised middleware) are used to enforce secure authorization between seller and buyer in real time. Symmetric key pools operate using a modified proof-of-authority mechanism to enforce the highest security with balanced decentralization.

### Other Notable Properties of Data Vaults
- Their design will enable true data sovereignty via a "proof of ownership" based design architecture. Detailed technical design of data vaults will be released in our "Yellow Paper" but at a high level - all datasets that include sensitive data will be encrypted with keys that belong solely to the data creator/owner. If a copy of the data is given to a new buyer, decentralised middleware will be used to mediate the handover of the copy to the new owner with encryption handled behind the scenes (to ensure UX is seamless). But in the case of a Data NFT, where the actual ownership of a data asset can move from one party to another - the  "proof of ownership" will also be transferred. This process will also be handled by the "decentralised middleware" service.

<br />
- Data Vaults will enable a user to "opt out" of the system in the event they do not want to share their data anymore (e.g. a requirement in GDPR). This is achieved by the above mentioned "proof of ownership" protocol. Where the unique decrypting key can be "burned" which then effectively makes all decentralised copies of data (e.g. in IPFS or elsewhere) become **untethered from the Data Creator**. The data without its decryption key is now effectively just a blob of scrambled test without any identity or utility attached to it. There are of course challenges to this that we need to solve, for e.g. what happens if you sell your data and then change your mind after the sale? Do we allow for a recall of data sale? if so, how can we ensure a user can completely opt-out?

<br />

> This feature is currently in the "Detailed Design & Prototyping" stage.



## Personal Data Adaptors <a name="data-adaptors-1"></a>


## Data Streams <a name="data-streams-1"></a>

You can let buyers subscribe to “personal data streams” — unlike the on-off datasets that can also be purchased on the Data Dex, data streams will continue to feed data once a “subscription” is purchased.

Streams are a more powerful way for buyers to subscribe to longitudinal datasets that grow over time. For example, health and wellness data like activity, sleep quality, blood pressure or financial activity like spend habits etc.

When paired with context rich data from your “data vault” — streams become a valuable and steady source of passive income for you in exchange for your personal data.

<br />

> This feature is currently in the "Detailed Design & Prototyping" stage.



## Trusted Computation Framework <a name="trusted-1"></a>

As personal datasets under the control of Data Coalitions grow overtime, certain end use-cases may require access to highly sensitive, identifiable data — often these use-cases will provide the most “payout” for data usage (as such they are considered high value use-cases). In such situations a trusted computation framework can be used to ensure computation is handled off-chain with tamper-proof integrity. The Data Coalition will coordinate these computation jobs on-chain (with possible coordination assistance of (Chainlink’s Attested Oracles)[https://blog.chain.link/driving-demand-for-enterprise-smart-contracts-using-the-trusted-computation-framework-and-attested-oracles-via-chainlink/])

All personal data traded on the on-chain DEX is never stored on-chain — only hash values are stored to ensure integrity of traded datasets. But in certain advanced use-cases where Data Coalition’s manage the data of multiple users, there will be encrypted personal meta data stored on-chain. There will be cases where this data cannot be put on-chain even when encrypted due to privacy regulations, especially if the blockchain network is spread across multiple geographies. Off-chain execution is, in some cases, the only option for processing this data. Trusted Computation Framework can be used to localise the computation of the data to ensure the data storage and processing complies with all data sovereignty regulations.

The trusted computation framework is tethered to the “regional decentralisation hub” and is our "Compute-to-Data” solution for highly sensitive data processing requirements within high regulatory environments.

<br />

> This feature is currently in the "Research:Labs" stage.



## Regional Decentralisation Hubs <a name="decen-hubs-1"></a>

Highly sensitive data like medical data from hospitals, personal health records, financial transaction or credit history are protected by regional or local sovereignty laws. To unlock the trade of this data we cannot use fully decentralised global storage or compute. For example; we may want to limit trade, storage and compute on data to only the EU region so that it complies with laws like GDPR and yet prevent a central hoarding of these resources

Regional Decentralised Hubs are a novel idea we are exploring around regional decentralisation which balance legal sovereignty laws with personal data sovereignty.

<br />

> This feature is currently in the "Research:Labs" stage.


## The Data Metaverse and nfME Avatar Technology <a name="nfme-1"></a>

nfME (Non Fungible ME) are your `Data Avatars of the Metaverse`. Join the Data DEX and complete a "seed profiler job" and have your very own nfME minted and stored in your wallet. nfME's have "personal data categories" (PDC) linked to it; these feed data into the nfME's and this data is secured in personal `Data Vaults`. Example PDCs are social, financial, historical, internal and external.

Apps built on Itheum's `data collection and analytics toolkit` feed data into the PDCs, these apps are run by Itheum as well as other organisations who want to generate high value data and then incentivise you to provide them access to your data. Itheum's `Personal Data Adaptors` can also discover and harvest on-chain and off-chain personal data and lock it inside your `Data Vault` and link it to your nfME.

As more data is added to the nfME; it's "data signature" changes and more "accessories" and "evolution traits" are made available to your nfME. This is akin to purchasing gaming accessories and traits to augment your in-game NFT characters. Your nfME is organic and grows like a human as more data is added to it.

### What can I do with an nfME?

- nfMEs are NFT tokens; so it supports all NFT capabilities. By your can never completely sell your nfME, you can only lease it to others and they can use it to access your data. It's a "authorisation key" your provide to a 3rd party for fair use of your data in return for shared value.
- Explore Itheum's `Virtual Data Metaverse` which is a digital metaverse data marketplace and interact with other nfME avatars and engage is missions or trade "accessories" or "evolution traits".
- Participate in governance of `Data Coalition DAOs` - These are bulk data trading DAOs that exist to serve the people and protect personal data. Stake and Farm with existing Data Coalition DAOs and provide data curation and data quality assessment services or give them access to your nfME and other data assets and allow them to trade your data on your behalf as part of a larger bulk dataset.
- Slice out certain segments of your data (e.g. Data from a specific app or category) and mint them into `Data NFTs` and sell these in secondary markets.


In the web2 world; your personal data is exploited by 3rd parties and large corporates... in Itheum's Data Metaverse; we give you true ownership of your data via your own Data Avatar... welcome to the era of the nfME.


<br />

> This feature is currently in the "Research:Labs" stage.



# Technology Philosophy

## Multi-Chain Strategy <a name="multi-chain-1"></a>
The Itheum Data DEX will work across EVM compatible chains from day one. We already have Ethereum, Polygon, BSC, Harmony, PlatON and Parastate working and will be deploying into Avalanche shortly. We are also working on a `native middleware interface` to enable support for non-EVM blockchains like Elrond, Algorand, Hedera and others. Currently data advertised on a particular chain can only be visible to participants who are one the same chain. i.e. a buyer can only buy data advertised for sale on the same chain.

We are working on cross-chain advertising and purchasing of data facilitated via cross chain oracles that will allow for the transaction handshake to be done between chains and allow for the data to be verified and transacted as well as for the mint/burn of chain native tokens to balance the chain specific token repositories (i.g. burning of Polygon tokens and minting of BSC tokens and vice versa as data is transacted across chains).

{% youtube 63BE4plzDzw %}
> _Demo video of the Itheum Data DEX working on Ethereum and Polygon_

## Multi-Chain Technical Design Goals <a name="multi-chain-1a"></a>

- Itheum is a "protocol" and not just a set of EVM contracts that make up a DApp. So this protocol can be implemented on any blockchain.
- The Itheum protocol is built into the smart contract layer. The protocol enforces 3 elements needed for data trade to happen on the blockchain; `Proof of Lineage, Provenance and Veracity`. We have pioneered a way to deliver this via a nice UX that abstracts all the complexity from the end-user.
- Therefore the protocol can be implemented in any blockchain and on any native runtime (does not have to be EVM). So long as the native chain supports transaction consensus and token standards; Itheum can be built on it.
- Itheum aims to be chain-agnostic and fully interoperable. We follow the same design principles as Chainlink - we define the standard set of rules (i.e. protocol), enforced in immutable smart-contracts which coordinate how data will be traded between parties. We will have interfaces in multiple blockchains that can coordinate the workload. Data platforms (like Itheum and Chainlink) need to be architectured this way as they form the foundation for future web3 core infrastructure. This also makes sure we can work across private, permissioned and public chains to reach maximum adoption.
- Itheum will have a single "primary chain" and multiple "side chains". The "primary chain" needs the best performance and have cost-efficiency (so we intend to pick the best EVM or non-EMV blockchain as our primary chain). We can then build our side chain smart-contract-coordinators on any other chain and runtime; and they can talk to each other via bridges, middleware and oracles.
- The future of blockchain is interoperability, so we are designing it this way.



## Cross Chain Tokens <a name="cross-chain-1"></a>
The core Itheum Data DEX token is an ERC20 token called MYDA (short for MYDAta). The MYDA token will allow for the purchasing of data from data creators as well as from Data Coalitions. The MYDA token will also play a role in staking against a Data Coalition and for decentralised governance of the Data Coalition’s responsibilities and actions.

As the Itheum Data DEX operates cross-chain, there will be core tokens that represent each chain with the total supply of MYDA bridged and distributed as more chains are added.

- MYDA — Token deployed on Ethereum
- mMYDA — Token deployed on Polygon/Matic
- bMYDA — Token deployed on Binance Smart Chain (BSC)
- aMYDA — Token deployed on Avalanche

MYDA can be moved between chains via native bridges that already exist. For example, you can use the native Polygon <> Ethereum token bridge to convert you MYDA to mMYDA and vice versa.



## Cross Chain Data Trade



## Per-User Encryption Strategy



## Decentralised Key Pools



## Moving to a Layer 1 Protocol
[talk about the bridges that are coming up to link chains to data like polygon filecoin bridge]


---



# Itheum’s role in web3



## Complex use cases



## Metaverse Data Layer



---



# Itheum Token <a name="intro-2"></a>
The “primary token” will exist on the Ethereum blockchain (Note that this is subject to change as we continue weighing the pros/cons of cross-chain adoption — as low transaction cost for trading of data is very critical for adoption of a platform like Itheum, we may move the primary token to a chains like Polygon, BSC, Avalanche or Elrond).

The primary token will have the token symbol MYDA and the side-chain tokens (called Side Tokens) will have a prefix character in front of the token symbol to identify it (e.g. mMYDA, bMYDA).

## Token Utility <a name="tokenomics-2"></a>
The MYDA token is a pure “utility token” as without owning MYDA you will not be able to use many features on the Itheum Data DEX to facilitate the open exchange of personal data.

At this point, the following tasks will REQUIRE the MYDA token (or corresponding Side Tokens) — as we design and write our smart contracts we will also take a MYDA 1st approach to aligning incentives so we can ensure that MYDA’s position as a utility token can’t be disputed:

**1) Gaining Access rights to use Data Packs / Data Streams / Data Coalition Data Pools**

The MYDA token is a pure “utility token” as without owning MYDA you will not be able to use many features on the Itheum Data DEX to facilitate the open exchange of personal data.

At this point, the following tasks will REQUIRE the MYDA token (or corresponding Side Tokens) — as we design and write our smart contracts we will also take a MYDA 1st approach to aligning incentives so we can ensure that MYDA’s position as a utility token can’t be disputed:

**1) Gaining Access rights to use Data Packs / Data Streams / Data Coalition Data Pools**

A Data Creator (who is the original Data Owner of the data) will allow an Access Requester to access their data via a transfer of MYDA between the parties. MYDA is essentially the key to use the data from an authorization perspective. The primary goal would be use the transaction of MYDA (between the 2 parties as logged on-chain) as:

- Evidence of access rights being granted by the Data Owner to another party
- To trace and have evidence of the lineage of data access
- To trace back access rights to a Provenance (Data Creator)

If the sale is done via a Data Coalition (i.e. as a bulk pool of data), the MYDA is transferred from the Access Requester to the DC DAO and then distributed to the members of the DC as follows:

- To the Data Creators to indicate access rights to use the data (as mentioned in the above section) 

- Based on the relative bond/stake token contribution of the board members, members and general stakers to highlight traceability of the effort spent by these parties to coordinate the bulk sale, flag and signal data quality and accept risk of remediating and mediating contentious sales. The transfer of MYDA to these parties is also used as lineage and audit to trace all parties involved in the data transfer process.

See point number (3) below for more details…

**2) Stake MYDA to have relative voting rights in the Itheum Foundation (IF) DAO**

The IF DAO will vote on "Proposals'' on how the MYDA Treasury will be spent to further Itheum's community development and roadmap.

**3) Stake/Bond MYDA to create a new Data Coalition (DC) (which is governed by a DAO)**

By doing so; you receive relative voting rights in return to manage the operation of the Data Coalition DAO (DC DAO). Staked MYDA goes into the "DC Fund Pool" - which is then used for arbitration and dispute resolution in contentious sales of data. The DC DOA votes on "Motions" related to the bulk sale of data via the DC. 

The following parties can Stake/Bond MYDA:

- Board Members will bond MYDA to flag their commitment to the DC and to act in the best interest of the Members. The bond is locked in for until the Board Member leaves the DC.

- Data Creators or Contributors (called Members) can link their data to a DC and also stake some MYDA to flag that they have genuine interest in supplying good quality data to the DC.

- Anyone (even those who do not want to provide data themselves) can stake MYDA into an existing DC DAO. They do this by becoming a "data quality verifier" (resulting in a Crowd Sourced Data Curation dynamic), effectively also signalling the "genuineness/credibility" of a Data Coalition (similar to how credibility of a node validator in a DPOS gets signalled by the community who delegates their stake with them). Everyone who stakes/bonds MYDA into are all incentivised relative to their role and stake and earn micropayments after each sale is finalised. Learn more about the [Data Coalition DAO design here][#data-coalitions-1]



## Token Metrics <a name="tokenomics-3"></a>

Please note that the following details are likely to change as we are currently planning for our token launch and as we adjust our token offering based on our planned token utility forecast.

**Total MYDA Supply: 1,000,000,000**

Token Generation Event (TGE) Offering:
- Hard Cap on Launch: 6.5 million
- Liquidity on DEX: 400k
- Total MYDA offered (13.8%): 138,000,000 (seed + private = 130,000,000, Public IDO = 8,000,000)
- Price per MYDA: 0.10
- Initial Market Cap: $450,000

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1yhdk5jekmby4nj2s0om.png)
 
![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/5p1usdq7u755ks33rce6.png)


## Token Distribution <a name="tokenomics-3"></a>
As with all blockchain based projects, there will be an allocation of tokens that are not for public sale, these non-sale tokens will be allocated to various buckets to oversee the roadmap, community, partners, liquidity and incentives needed for continued growth of the Itheum ecosystem and to ensure we build a platform that becomes a market leader, that brings the best value to the community and eventually be governed by the community. The allocations will be as follows:

### Foundation Reserve


### Liquidity


### Community & Ecosystem


### Partners


### Team & Advisors






## Active Community and Loyalty Incentives <a name="tokenomics-3"></a>
-------- Talk about how we are planning to put in tx fees for trade and have that money moved to a special tresury. This treasury is then split and shared with the ecosystem, Where a % goes to tokens holders and % goes to fund more apps, data coaltions and integrations

---


# Usage, Utility & Fraud <a name="intro-2"></a>

## Fraud Detection — “Gaming” the system <a name="fraud-1"></a>

As detailed in the above sections, the Itheum Data DEX allows for the sale of personal datasets. The reward for each sale will be paid out in the platform’s native MYDA utility tokens. As the demand for MYDA tokens grow we anticipate there will be malicious individuals or parties that try and “game the system” with the intention of obtaining MYDA or to disrupt the market activity of legitimate data trade. 

### Types of Attacks <a name="fraud-2"></a>
The following are some attack scenarios we anticipate:

#### 1. Selling Fake Data
A malicious user or a botnet can potentially spin up 100s of addresses and upload fake data files. The intention here would be to spray attack dummy datasets and mask them as legitimate datasets. For e.g. If a Data Coalition that aligns with the “sale of health data for commercial use-cases” has a high return in terms of sales — the malicious party can upload fake data and tag it as legitimate blood pressure readings. The malicious party can then align to the above Data Coalition and the data is then piped into the Data Coalition’s data pool. This kind of attack will diminish the data quality of the overall Data Coalition as buyers will rate the pool data quality as low and/or request refunds. The malicious parties intention would be to attempt to pass for legitimate data and in return earn some MYDA tokens before the act is discovered and blacklisted.

The attack can also happen in a direct peer-to-peer sale method, where the malicious user uploads fake data, write up an appealing and legitimate data preview headline and hope that a buyer will be tricked into making the MYDA transfer before discovering the data is fake.

####2) Selling “Doctored Data”
This is similar to the above attack but instead of uploading and selling fully fake data, the Data Creator/Seller doctors or manufactures data to look like it’s accurate. For example, as blood pressure data has a standard “mask” (e.g. 123/89) they can generate some random data that looks like accurate data (134/32, 123/90). They can use scripting to generate bulk quantities of doctored data and automate the upload and sale of it as described in the above section (i.e. via a Data Coalition or direct peer-to-peer sale)

####3) DDOS/Spam via Fake Orders
This is very similar to the attack described in the "Selling Fake Data" section but the intention here is more to disrupt the natural marketplace activity by spamming it with fake data orders that make it impossible for legitimate orders to be viewed and purchased. The attacker/s can spin up multiple identities and advertise small bits of data for sale until they pollute the marketplace or the Data Coalition’s data pools with fake activity.

####4) Uploading Irrelevant/Inappropriate Data 
In this type of attack, a malicious user will attempt to bring reputation damage to the Itheum Data DEX by uploading irrelevant or inappropriate data. They may masquerade as a legitimate user and then disrupt the credibility of the platform by uploading bad data that will be seen up other legitimate users of the platform. This may also bring about regulation concerns if the data is especially inappropriate. Over time this type of attack will "spam" the natural, organic network activity and degrade the reputation of the Itheum Data DEX.

####5) Sybil Attack
This type of attack is something all distributed systems and blockchains are prone to and involves malicious parties using “multiple identities” to flood a chain with the intention to take control of governance or core functionalities (like producing blocks in a blockchain or voting in their fake proposals). The Itheum Data DEX is built on EVM compatible chains (Ethereum, Polygon etc) — so the inherent risk of Sybil attacks on the core chains will impact Itheum’s data trade activity. The Itheum Data DEX is also prone to Sybil Attacks of a different type; where a malicious user, masquerading as a Data Creator/Seller can spin up multiple identities and flood the marketplace with fake orders or attempt to take control of the governance and voting activities that are core to the Data Coalitions.



## Methods for Fraud Prevention <a name="fraud-3"></a>

The following methods are (or will be) implemented to mitigate the above attack vectors.

<br />
- The selling of personal data (either via direct peer-to-peer sales or via a Data Coalition) involves an “advertising process” (described in a section above) — where the integrity of the raw data is advertised on-chain to facilitate the trade process. As this is a “write-transaction” it does require GAS to complete. If a malicious user is attempting to spam or dump fake datasets for sale on the marketplace, the GAS cost implication will make it impractical. (this is especially true if the chain is Ethereum, but for low GAS fee chains like Polygon — the risk still remains but at lower levels). This is applicable for direct peer-to-peer sales of Data Sets as well as for sales of Data NFTs.

<br />
- Currently a Data Preview is attached to each Data Set and Data NFT sale offer. When a user puts “Data Previews” they are currently manually entered, this allows for a malicious user to put in a fake preview and upload fake data.

    ![image](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/xdn1bxsxdqkbclw1rhkn.png)
    > _Data Previews can be “Gamed” as it’s manually entered_

We are working on having a new meta data field called “data snapshot” which will focus on a specific, random part of the uploaded file or stream and attach that to the dataset order. In order to prevent the “data snapshot” exposing any sensitive data; upon upload of the data file by the seller they will be provided with a few “snapshots” and they will be able to pick one that they prefer (similar to how you can pick a generated thumbnail for a video uploaded in YouTube)

<br />
- Data Creators/Sellers can align to a Data Coalition to leverage “power selling” of datasets. To align to a Data Coalition and then pipe their data to the Coalition for sale, the Data Creator/Seller will need to stake some MYDA against the Coalition DAO. The more they stake, the higher the data quality score is attached to the origin Data Creator. This puts a “skin in the game” vector for the Data Creator/Seller to behave in ways that don’t end up them having to be penalised and have their MYDA revoked.

<br />
- Staking/Voting against a Data Asset to boost credibility: We are looking at methods to attach community staking and/or voting against data assets that are put for sale. This may be voting that happens as part of the Data Coalition (i.e. if specific user’s data is gaining more demand, the DAO upvotes the user’s credibility). As the core credibility grows the value of the user’s data (in terms of MYDA cost) also increases. Based on this method, as a new Seller (i.e. new’ish Chain Address) tries to sell data, the credibility score will be extremely low and therefore the return will be less — this provides the organic incentive needed for legitimate behaviour as the best way to earn more MYDA would be to upload legitimate data, align to strong Data Coalitions and gain organic credibility over time.

This approach will organically generate a sort of **confidence score** for each dataset or data NFT being sold on the marketplace. This is very similar to the OpenSea Confidence Score dialog alert you see when you attempt to buy NFTs.

![image](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7c2myf0dtjl5ja7841je.png)

>_OpenSea Confidence Score notification for purchases_

<br />
- Multi Account Detection and Blacklisting: We currently use Moralis for user account management. (Moralis)[https://moralis.io/] allows for multiple addresses to be linked behind the scenes to a single user. This enables to have an audit trail of a users trying to launch any potential address based sybil attacks and allow us to blacklist transactions in real time.

<br />
- Verified Identity and/or KYC of Data Seller: One method to prevent most attacks described above would be to use a Verified Identity or KYC platform to ensure that the Data Seller have gone through a verification process before they can sell their data. To prevent a high barrier to entry and boost adoption with a better UX, we may allow for a “unverified” sale of data which will allow for the sale of data but with limited functionality in the DEX and/or much lower MYDA earnings (this is to incentivise the user to verify — this is similar to CEX’s like Binance which allow for trading smaller amount without verification). We are also investigating the (BrightID)[https://www.brightid.org/] project for fully decentralised proof of uniqueness and other mainstream KYC platforms like CIVIC as potential solutions.

<br />
- To increase the legitimacy of Data DEX user accounts and to prevent the attacks that we describe above; we are also considering using a mobile phone number as a 2nd factor on the user identity record. This solution path makes sense should we not want to proceed with a full KYC tool and to yet ensure each user has a 2nd factor they need to *prove they own* before using the Data DEX. As obtaining a mobile number has compliance and audit trail attached to it (you need to provide your driver's license or prove your identity and address for example), this makes attacking the system very impractical as each user will generally only have access to one mobile number (of course, there are exceptions to this but it's not possible for a single user to own hundreds of mobile numbers for example).

<br />
- To prevent dump botnet attacks we will implement "invisible CAPTCHA". These are modern captcha technologies that don't have the bad UX of traditional captcha (i.e. click a button on select patterns from photos) but can weed out fraudulent automated users or bots with very high accuracy.

We are sure that there will be many more methods malicious users will use to try and game and disrupt the Itheum Data DEX and marketplace ecosystem. As part of our core governance model and token distribution we will reserve a potion for the community to investigate new attack vectors and incentivise this type of white-hat hacking and remediation behaviour to continue to boost the security of our Data DEX.



##  Core Utility (compare itheum to NFT and how we provide veracity, provancne and linage)



---



# Decentralised Governance <a name="governance"></a>
The Itheum platform will aim to be a `public-goods platform that's fully decentralised`. Public-goods in a sense that all the technological developments that are made as part of Itheum's vision will always be available in the public domain and not privatised in any way. Although it will take some time to fully get there; especially in the area of our web2 data on-ramp/bridge technology (e.g. Data Collection and Analytics Toolkit). But it's worth nothing that our web3 technology stacks will be fully available in the public-domain from day one. 

With our technology deliverables aligned to be made available as a fully public-goods platform, the next important aspect to decentralisation is to have our technology development roadmap DAO controlled with MYDA token holders being able to collectively and fairly decide on the technology strategy and direction of roadmap delivery. It's worth nothing that "fully DAO controlled" platforms are complex to setup and will require some platform operating maturity before implementing, but the ultimate intention of Itheum is full decentralisation and this will happen progressively over time in order to ensure the Itheum platform will remain in the hands of the public - but at the same time, be a robust operating technology solution that will be around for the next 100 years. Until the platform roadmap is progressively transformed into a fully DOA controlled element, the Core Team will manage the prioritised of the roadmap items with some pathways detailed on how the platform will transition to decentralisation. This is described below in the "Foundation DAO" section.

Once the Itheum platform transforms into having its operations and roadmap strategy DAO controlled, the intention is to have the native token (MYDA) be the governance token. New advanced yet seamless DAO schemes will be build around the MYDA token that will increase the utility of the MYDA token and to also ensure the best user experience for our platform users and token holders. People who own MYDA will be able to participate in DAO votes and collectively make decisions on the future of Itheum.

Itheum has 2 high-level forms of DAO schemes that will be implemented in our platform:
1. Foundation DAO: This is the platform governance DAO that will eventually be responsible for the future direction of Itheum's technology strategy and roadmap. 

2. Data Coalitions DAO: Unlike the single Foundation DAO, there can be multiple Data Coalition DOAs. Each time a new Data Coalition is setup by the public and the structure reaches an "operating mode" it can be considered to be an independent DAO. The overarching parameters of the Data Coalitions DAO will be controlled by the Foundation DAO. So effectively, the Foundation DAO is considered to be a `DAO of DAOs`.

## Platform Governance - Foundation DAO <a name="governance-1"></a>
As detailed above; the Foundation DAO will be responsible for the core platform's governance activities. Until the Itheum platform reaches the `operational maturity` required to fully decentralise the Foundation DAO, the Core Team will provide the governance in away that's fully open to public visibility and accountability.

### Operational Maturity <a name="governance-1-1"></a>
In this section we will clearly detail what it means when we say `operational maturity` and this dictates when Itheum will progressively transition to a fully DAO controlled Foundation DAO. For an ambitious platform like Itheum to gain widespread mainstream adoption and deliver robust technology solutions in the midst of high competition from other commercial and public organisations - we will need to have fast iterative delivery of roadmap items an make objective decisions to ensure we get Itheum to the Mainnet in a state that makes it the number 1 data platform for web3.

It's a well known observation that putting in a fully decentralised DAO too early can slow down decision making and delay competitive timelines and therefore we need to be cognisant and pragmatics on how early we embrace full decentralisation, as failure to do so will put the entire Itheum platform delivery at risk and effect all of the itheum community and token holders. Once Itheum has been deployed to the Mainnet and the day-to-day operations of the platform are in a stable and controlled state and we are ready to move into iterative continuous improvements; we will then begin rolling out the Foundation DAO schemes and start opening up public voting for further roadmap upgrades. Such an approach will ensure the long term success of itheum and is in the best interests of the entire community.

### Roadmap methodology <a name="governance-1-2"></a>
Itheum's roadmap has always been public and is available for everyone to view. It can be accessed here: https://itheum.com/roadmap

As seen in the roadmap board; all items that need to be considered to be included in the roadmap are added here and are voted on by the Foundation DAO to transition them to the appropriate lanes for delivery. We follow the Kanban methodology to manage the transition of items from inception to delivery. An idea is registered in the `IdeaBox` and can then move to `Research and Development` after the Foundation DAO voting agrees that the core-team can spend the time and effort to commence R&D activity on the task. Once R&D is complete and the team is ready to ready to begin design and estimation; the task will then move to the `Estimating` lane. The Foundation DAO then can decide when to schedule in the work. Once it's ready to start the development phase it will then move to the "Sprint Candidate" lane and then development and testing begins. The final lane is called `shipped` and an item moves there once it's deployed to production (and/or mainnet).

### DAO Technology Schemes <a name="governance-1-2"></a>
The Foundation DAO feature is still under development but we detail our current design schemes goals below, please note that this is subject to change as we iterate on our design and we will continue to keep this section of the whitepaper updated with any changes and also inform our community via our channels of any changes.

- The MYDA token also plays the role of a Governance Token. There wont be any other, dedicated governance token in Itheum. This ensure MYDA has more utility int the Itheum ecosystem and that there also wont be a proliferation of bespoke governance and other tokens in Itheum - this boosts the user experience of the platform as it keeps things simple.
- Voting is by `Quorum + Direct Democracy`
- MYDA holders can stake their tokens into the Governance contract and in turn they will be able to vote on `proposals`
- The weight of each user’s vote is proportionate to the amount of tokens they have staked
- Users can exist their stake anytime, but their vote will be withdraw if they exit during an active voting round
- `Proposals` can be decisions to `roadmap updates` or `changes to core platform parameters`
- **Core Platform Parameters** can be tasks like `Update Quorum %`, `Approve new Data Coalition applications`, `Manage core Data Coalition parameters (min:max members / min fees to join)`, `Setting Harberger Tax rate on Coalitions managing Data NFTs`, `Manage Key-pool parameters for Personal Data Vault nodes (max / min / rotation / bonds)`, `Manage node parameters for Trusted Computation framework (max / min / rotation / bonds)` etc.
- **Roadmap updates** are bascially proposals to move the development roadmap future (see above in Roadmap methodology section)
- Potential issues with this scheme that we will need to design around are `Governance Locks if quorum is not reached` and `Whale dominance`


## Data Coalition DAOs <a name="governance-2"></a>
Details about the Data Coalition DAOs are explained in the above section titled [Data Coalitions](#data-coalitions-1), but we will summarise the DAO scheme below to lay out the various features of this component. Please note that this is subject to change as we iterate on our design and we will continue to keep this section of the whitepaper updated with any changes and also inform our community via our channels of any changes.

- These DAOs are generated each time a new Data Coalition is formed and approved by the Foundation DAO to operate.
- These DAOs are programmatically built via a factory contract that generates the base Data Coalition DAO according to the core parameters (these parameters can be altered later by the Board Members of the DOA).
- Anyone can form a Data Coalition DAO by bonding MYDA. The creator is called the `Chairman` but they don't have any special rights. They have the same rights as `Board Members`.
- Once the Chairman creates the DAO, it goes into a phase where new Board Members need to be recruited. Board Members also need to bond MYDA and be voted in by the other Board Members. This is akin to `Permissioned entry` where existing Board Members need to recommend you via a `Motion`
- Only Board Members can vote on Motions; which follows a `representative democracy` scheme. A Motion can be anything that ranges from `adding more Board Members` to `changing the parameters of DAO (min:max members / min fees to join, terms of sale, sale price etc)` and also to `agree on which purchase request to approve (i.e. who to sell data to)`.
- Voting is by `Simple Majority (no quorum needed)`, this allows for fast decisions to be made on potential new data sales.
- All funds raised via bonds and stakes go into a `DC Fund Pool` which is then used for arbitration and dispute resolution in contentious sales of data.
- The DC Fund Pool will be controlled by a Multi-Sig Wallet that will require a minimum set of Board Member signatures to process transactions.
- Once the minimum Board members have joined the Data Coalition, it will enter into "operational mode" where it can start accepting `Members`.
- Board Members will provide some public profile information to provide transparency on who they are, this is to provide some information for future Members to make informed decisions on if they should join the Coalition. This is very similar to how the `Delegated Proof of Stake validator selection` process works, where you can stake your tokens after doing some due-diligence on the validators reputation and past performance.
- Anyone can link their data to a Data Coalition and join as a `Member`. They can also choose to Stake MYDA along with their data to provide more guarantee that they are aligned to the long term mission of the Data Coalition.
- Everyone who joins the Data Coalition (Board Members and Members who contribute data) - start with a low reputation score that builds up over time with each successful data trade.
- Data Coalitions also allow for "pure staking" of MYDA, where anyone can stake their MYDA into a Coalition (you don't HAVE to provide your data) to flag their support for the Data Coalition and to signal that the data within the Coalition is good (Crowd Sourced Data Curation). They are also considered to be a `Member`.
- Members who staked MYDA and Board Members get a majority share of each sale. A minority share is available for pure stakers, data providers who did not “stake” and/or who have a low reputation
- Members can exit anytime but Board Members need a Motion passed to leave or be replaced. Board Members also need to wait until bond period ends to exit.
- Although not mandatory, Members will be able to participate in ongoing period votes to express satisfaction of the Board's performance. If satisfaction rates are low for multiple voting points - this will trigger a board rotation clause.
- Although not mandatory, Members will be able to expect the Board to have a fixed term, and after which they will need to rotate out and be replaced with a new board. 
- A Data Coalition can only be shut down if it's not `operational`, if it does not have any outstanding disputes to resolve, all Board Members and Members have been compensated for any sales made in the past. The final decision will be made by the foundation DAO to terminate operation.



---



# Product Development <a name="intro-2"></a>



## Roadmap <a name="intro-2"></a>



## Our 5-stage Product Development Process <a name="product-process-1"></a>
To ensure we continually innovate and delivery tangible web3 / blockchain features to market - we will use a simple 5-stage product development process. All our features will continually be categorised as per these stages to ensure progress is transparent to our community.

1. **Research : Labs** - Ideas we are running through R&D.
2. **Detailed Design & Prototyping** - Ideas that pass our labs stage and we are doing detailed solution architecture with release candidates for the testnets.
3. **Available in Testnet** - Iterative builds being released to testnet, until product update is tested and signed off by our community and is ready for deployment to mainnet.
4. **Security Audits** - Final release that goes through internal and external security audits.
5. **Available in Mainnet** - Released to mainnet.



## Team and Partners <a name="intro-2"></a>



---



# Key Terms of Reference <a name="refs-1"></a>
- **Data Creator:** The type of user who generates the raw data (i.e. the data is an extension to them and would not exist if they did not generate it). This is usually the user who uses an app built using Itheum’s data collection and analytics toolkit.

<br />
- **Data Seller:** A Data Creator who uses the DEX to sell their data either as a direct Data Pack sale or Data NFT.

<br />
- **Data Owner:** The type of user who owns a piece of data that’s available in the decentralised data DEX/marketplace. The Owner does not have to be the Data Creator, it can be someone who purchased a Data Pack or a Data NFT can can prove ownership of that asset on the blockchain. So for each Data Pack for example, there will be 1 Data Creator and potentially multiple, unlimited (n∞) Data Owners (the users who bought the original data pack). And for Each Data NFT for example, there will be 1 Data Creator and a single (n1)or multiple, limited (nx) Data Owners as Data NFTs have a limited supply of 1 — x.

<br />
-  **Buyer (Access Requester):** The type of user who logs into the decentralised data DEX and buys a Data Pack or Data NFT. They then become a Data Owner. They are also referred to as a `Access Requester` as they are technically not "buying data to fully own it", instead they are only "buying access rights to use a copy of the data".

<br />
- **Data Pack:** The simplest dataset that can be sold on the Data DEX. It’s a file in JSON format that can be put on sale by the Data Creator and then get’s advertised for sale in the marketplace. The sale happens directly between Creator and Buyer with no intermediaries.

<br />
- **Data Order:** When a buyer buys a Data Pack a Data Order is created. This has some meta data around the transaction, this information is kept off-chain (to conserve on-chain resources and keep costs low) but can be verified to be accurate on-chain.

<br />
- *Data NFT:* The alternate way to sell data is by wrapping it in a NFT and then trading it as a regular NFT product in the NFT marketplace.



--- 



# Disclaimers <a name="disclaimers"></a>
This Whitepaper and any other documents published in association with it including the related token sale terms and conditions (the Documents) relate to a potential token (Token) offering to persons (contributors) in respect of the intended development and use of the network by various participants. The Documents do not constitute an offer of securities or a promotion, invitation or solicitation for investment purposes. The Documents are not intended to be a financial services offering document or a prospectus. The token offering involves and relates to the development and use of experimental software and technologies that may not come to fruition or achieve the objectives specified in this White Paper. The purchase of Tokens represents a high risk to any contributor. Tokens do not represent equity, shares, units, royalties or rights to capital, profit or income in the network or software or in the Token issuing entity or any other entity or intellectual property associated with the network or any other public or private enterprise, corporation, foundation or other entity in any jurisdiction. The Token is not therefore intended to represent a security or similar legal interest.
The purchase of Tokens involves significant risks and prior to purchasing them, you should carefully assess and take into account the potential risks including those described in the Documents and on our website.
Although there may be speculation on the value of the Tokens, we disclaim any liability for the use of Tokens in this manner. A market in the Tokens may not emerge and there is no guarantee of liquidity in the trading of the Tokens nor that any markets will accept them for trading.
This Whitepaper describes a future project and contains forward-looking statements that are based on our beliefs and assumptions at the present time. The project envisaged in this Whitepaper is under development and being constantly updated and accordingly, if and when the project is completed, it may differ significantly from the project set out in this whitepaper. No representation or warranty is given as to the achievement or reasonableness of any plans, future projections or prospects and nothing in the Documents is or should be relied upon as a promise or representation as to the future.